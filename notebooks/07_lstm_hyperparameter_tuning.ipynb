{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31eafbe8-9a12-4fb7-a52a-7aaf596e02b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout, LSTM, GRU\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "np.random.seed(0) \n",
    "tf.random.set_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e852d40-2cae-4e44-b5e5-a742f6340006",
   "metadata": {},
   "source": [
    "### Loading data and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbc43ef1-2b5a-4bb2-bff3-7800f4742dfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Volume</th>\n",
       "      <th>LogVolume</th>\n",
       "      <th>DiffLogVolume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Production Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-01-01</th>\n",
       "      <td>67515553.0</td>\n",
       "      <td>18.027869</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-01</th>\n",
       "      <td>61664960.0</td>\n",
       "      <td>17.937226</td>\n",
       "      <td>-0.090642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-03-01</th>\n",
       "      <td>66342950.0</td>\n",
       "      <td>18.010348</td>\n",
       "      <td>0.073122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-04-01</th>\n",
       "      <td>67719040.0</td>\n",
       "      <td>18.030878</td>\n",
       "      <td>0.020530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-05-01</th>\n",
       "      <td>66484591.0</td>\n",
       "      <td>18.012481</td>\n",
       "      <td>-0.018397</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Volume  LogVolume  DiffLogVolume\n",
       "Production Date                                      \n",
       "2015-01-01       67515553.0  18.027869            NaN\n",
       "2015-02-01       61664960.0  17.937226      -0.090642\n",
       "2015-03-01       66342950.0  18.010348       0.073122\n",
       "2015-04-01       67719040.0  18.030878       0.020530\n",
       "2015-05-01       66484591.0  18.012481      -0.018397"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Monthly_oil_data.csv', index_col='Production Date', parse_dates=True)\n",
    "df['LogVolume'] = np.log(df['Volume'])\n",
    "df['DiffLogVolume'] = df['LogVolume'].diff()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190befc7-c38e-48be-bb46-392c69382429",
   "metadata": {},
   "source": [
    "### Supervised Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8b77d97-6879-4086-8ab5-f2c52230d3c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape (112, 12) Y.shape (112,)\n"
     ]
    }
   ],
   "source": [
    "series = df['DiffLogVolume'].to_numpy()[1:] \n",
    "\n",
    "T = 12\n",
    "X = [] \n",
    "Y = []  \n",
    "for t in range(len(series) - T):\n",
    "    x = series[t:t+T] \n",
    "    X.append(x) \n",
    "    y = series[t+T] \n",
    "    Y.append(y)\n",
    "\n",
    "X = np.array(X).reshape(-1, T) \n",
    "Y = np.array(Y)\n",
    "N = len(X) \n",
    "print('X.shape', X.shape, 'Y.shape', Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fcda654-03ea-4260-b2bb-d5fd7ac34601",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "811081dd-c2c8-427b-9080-32082085a007",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ntest = 12  \n",
    "train = df.iloc[:-Ntest] \n",
    "test = df.iloc[-Ntest:] \n",
    "\n",
    "Xtrain, Ytrain = X[:-Ntest], Y[:-Ntest] \n",
    "Xtest, Ytest = X[-Ntest:], Y[-Ntest:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd9b113-52b4-4f4d-904e-6d57b132c8b1",
   "metadata": {},
   "source": [
    "### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "788b6ddc-ad09-4741-974a-7182770b8c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_x = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler_y = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "Xtrain = scaler_x.fit_transform(Xtrain)\n",
    "Xtrain = Xtrain.reshape(Xtrain.shape[0], Xtrain.shape[1], 1)\n",
    "\n",
    "Xtest = scaler_x.transform(Xtest)\n",
    "Xtest = Xtest.reshape(Xtest.shape[0], Xtest.shape[1], 1)\n",
    "\n",
    "Ytrain = scaler_y.fit_transform(Ytrain.reshape(-1, 1))\n",
    "Ytest = scaler_y.transform(Ytest.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefcba88-cbf7-45f1-8339-3ae9c39d074e",
   "metadata": {},
   "source": [
    "### Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab28a26e-9426-4899-a24d-47d7e861ca73",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx = df.index <= train.index[-1] \n",
    "test_idx = ~train_idx "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f99991-1fa0-4437-9f2f-10d4e80ec34d",
   "metadata": {},
   "source": [
    "### Manual Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab11b030-d019-417f-b1f2-287bdde6e703",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_and_train_lstm(units, dropout_rate, learning_rate, epochs, batch_size):\n",
    "    model = Sequential([\n",
    "        Input(shape =(T, 1)),\n",
    "        LSTM(units, activation='tanh', return_sequences=True),\n",
    "        Dropout(dropout_rate),\n",
    "        LSTM(units, activation='tanh'),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mse')\n",
    "\n",
    "    early_stop = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=15,  # Stop if no improvement for 15 epochs\n",
    "        restore_best_weights=True,  # Restore weights from best epoch\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    history = model.fit(\n",
    "        Xtrain, Ytrain,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(Xtest, Ytest),\n",
    "        callbacks=[early_stop],\n",
    "        verbose=0,\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    # Get final validation loss\n",
    "    val_loss = history.history['val_loss'][-1]\n",
    "    best_val_loss = min(history.history['val_loss'])\n",
    "    \n",
    "    return model, val_loss, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ba6f97b-cd81-45b8-a5c6-4e946506eb44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sadar\\anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "Testing: units=32, dropout=0.1, lr=0.001, epochs=50, batch_size=16\n",
      "  Validation Loss: 0.024159\n",
      "\n",
      "Testing: units=32, dropout=0.1, lr=0.001, epochs=50, batch_size=32\n",
      "  Validation Loss: 0.024429\n",
      "\n",
      "Testing: units=32, dropout=0.1, lr=0.001, epochs=100, batch_size=16\n",
      "  Validation Loss: 0.024485\n",
      "\n",
      "Testing: units=32, dropout=0.1, lr=0.001, epochs=100, batch_size=32\n",
      "  Validation Loss: 0.024565\n",
      "\n",
      "Testing: units=32, dropout=0.1, lr=0.0001, epochs=50, batch_size=16\n",
      "  Validation Loss: 0.024437\n",
      "\n",
      "Testing: units=32, dropout=0.1, lr=0.0001, epochs=50, batch_size=32\n",
      "  Validation Loss: 0.024104\n",
      "\n",
      "Testing: units=32, dropout=0.1, lr=0.0001, epochs=100, batch_size=16\n",
      "  Validation Loss: 0.024494\n",
      "\n",
      "Testing: units=32, dropout=0.1, lr=0.0001, epochs=100, batch_size=32\n",
      "  Validation Loss: 0.024175\n",
      "\n",
      "Testing: units=32, dropout=0.2, lr=0.001, epochs=50, batch_size=16\n",
      "  Validation Loss: 0.023757\n",
      "\n",
      "Testing: units=32, dropout=0.2, lr=0.001, epochs=50, batch_size=32\n",
      "  Validation Loss: 0.024781\n",
      "\n",
      "Testing: units=32, dropout=0.2, lr=0.001, epochs=100, batch_size=16\n",
      "  Validation Loss: 0.023038\n",
      "\n",
      "Testing: units=32, dropout=0.2, lr=0.001, epochs=100, batch_size=32\n",
      "  Validation Loss: 0.024435\n",
      "\n",
      "Testing: units=32, dropout=0.2, lr=0.0001, epochs=50, batch_size=16\n",
      "  Validation Loss: 0.024112\n",
      "\n",
      "Testing: units=32, dropout=0.2, lr=0.0001, epochs=50, batch_size=32\n",
      "  Validation Loss: 0.024186\n",
      "\n",
      "Testing: units=32, dropout=0.2, lr=0.0001, epochs=100, batch_size=16\n",
      "  Validation Loss: 0.024128\n",
      "\n",
      "Testing: units=32, dropout=0.2, lr=0.0001, epochs=100, batch_size=32\n",
      "  Validation Loss: 0.024344\n",
      "\n",
      "Testing: units=32, dropout=0.3, lr=0.001, epochs=50, batch_size=16\n",
      "  Validation Loss: 0.023531\n",
      "\n",
      "Testing: units=32, dropout=0.3, lr=0.001, epochs=50, batch_size=32\n",
      "  Validation Loss: 0.023908\n",
      "\n",
      "Testing: units=32, dropout=0.3, lr=0.001, epochs=100, batch_size=16\n",
      "  Validation Loss: 0.023142\n",
      "\n",
      "Testing: units=32, dropout=0.3, lr=0.001, epochs=100, batch_size=32\n",
      "  Validation Loss: 0.023839\n",
      "\n",
      "Testing: units=32, dropout=0.3, lr=0.0001, epochs=50, batch_size=16\n",
      "  Validation Loss: 0.024088\n",
      "\n",
      "Testing: units=32, dropout=0.3, lr=0.0001, epochs=50, batch_size=32\n",
      "  Validation Loss: 0.024104\n",
      "\n",
      "Testing: units=32, dropout=0.3, lr=0.0001, epochs=100, batch_size=16\n",
      "  Validation Loss: 0.024182\n",
      "\n",
      "Testing: units=32, dropout=0.3, lr=0.0001, epochs=100, batch_size=32\n",
      "  Validation Loss: 0.024271\n",
      "\n",
      "Testing: units=50, dropout=0.1, lr=0.001, epochs=50, batch_size=16\n",
      "  Validation Loss: 0.023297\n",
      "\n",
      "Testing: units=50, dropout=0.1, lr=0.001, epochs=50, batch_size=32\n",
      "  Validation Loss: 0.024440\n",
      "\n",
      "Testing: units=50, dropout=0.1, lr=0.001, epochs=100, batch_size=16\n",
      "  Validation Loss: 0.018436\n",
      "\n",
      "Testing: units=50, dropout=0.1, lr=0.001, epochs=100, batch_size=32\n",
      "  Validation Loss: 0.024182\n",
      "\n",
      "Testing: units=50, dropout=0.1, lr=0.0001, epochs=50, batch_size=16\n",
      "  Validation Loss: 0.024083\n",
      "\n",
      "Testing: units=50, dropout=0.1, lr=0.0001, epochs=50, batch_size=32\n",
      "  Validation Loss: 0.024381\n",
      "\n",
      "Testing: units=50, dropout=0.1, lr=0.0001, epochs=100, batch_size=16\n",
      "  Validation Loss: 0.024267\n",
      "\n",
      "Testing: units=50, dropout=0.1, lr=0.0001, epochs=100, batch_size=32\n",
      "  Validation Loss: 0.024394\n",
      "\n",
      "Testing: units=50, dropout=0.2, lr=0.001, epochs=50, batch_size=16\n",
      "  Validation Loss: 0.024791\n",
      "\n",
      "Testing: units=50, dropout=0.2, lr=0.001, epochs=50, batch_size=32\n",
      "  Validation Loss: 0.024481\n",
      "\n",
      "Testing: units=50, dropout=0.2, lr=0.001, epochs=100, batch_size=16\n",
      "  Validation Loss: 0.021420\n",
      "\n",
      "Testing: units=50, dropout=0.2, lr=0.001, epochs=100, batch_size=32\n",
      "  Validation Loss: 0.024772\n",
      "\n",
      "Testing: units=50, dropout=0.2, lr=0.0001, epochs=50, batch_size=16\n",
      "  Validation Loss: 0.024050\n",
      "\n",
      "Testing: units=50, dropout=0.2, lr=0.0001, epochs=50, batch_size=32\n",
      "  Validation Loss: 0.024296\n",
      "\n",
      "Testing: units=50, dropout=0.2, lr=0.0001, epochs=100, batch_size=16\n",
      "  Validation Loss: 0.024293\n",
      "\n",
      "Testing: units=50, dropout=0.2, lr=0.0001, epochs=100, batch_size=32\n",
      "  Validation Loss: 0.024114\n",
      "\n",
      "Testing: units=50, dropout=0.3, lr=0.001, epochs=50, batch_size=16\n",
      "  Validation Loss: 0.024333\n",
      "\n",
      "Testing: units=50, dropout=0.3, lr=0.001, epochs=50, batch_size=32\n",
      "  Validation Loss: 0.024013\n",
      "\n",
      "Testing: units=50, dropout=0.3, lr=0.001, epochs=100, batch_size=16\n",
      "  Validation Loss: 0.022948\n",
      "\n",
      "Testing: units=50, dropout=0.3, lr=0.001, epochs=100, batch_size=32\n",
      "  Validation Loss: 0.023755\n",
      "\n",
      "Testing: units=50, dropout=0.3, lr=0.0001, epochs=50, batch_size=16\n",
      "  Validation Loss: 0.024034\n",
      "\n",
      "Testing: units=50, dropout=0.3, lr=0.0001, epochs=50, batch_size=32\n",
      "  Validation Loss: 0.024072\n",
      "\n",
      "Testing: units=50, dropout=0.3, lr=0.0001, epochs=100, batch_size=16\n",
      "  Validation Loss: 0.024028\n",
      "\n",
      "Testing: units=50, dropout=0.3, lr=0.0001, epochs=100, batch_size=32\n",
      "  Validation Loss: 0.024156\n",
      "\n",
      "Testing: units=64, dropout=0.1, lr=0.001, epochs=50, batch_size=16\n",
      "  Validation Loss: 0.024190\n",
      "\n",
      "Testing: units=64, dropout=0.1, lr=0.001, epochs=50, batch_size=32\n",
      "  Validation Loss: 0.024783\n",
      "\n",
      "Testing: units=64, dropout=0.1, lr=0.001, epochs=100, batch_size=16\n",
      "  Validation Loss: 0.015141\n",
      "\n",
      "Testing: units=64, dropout=0.1, lr=0.001, epochs=100, batch_size=32\n",
      "  Validation Loss: 0.023893\n",
      "\n",
      "Testing: units=64, dropout=0.1, lr=0.0001, epochs=50, batch_size=16\n",
      "  Validation Loss: 0.024173\n",
      "\n",
      "Testing: units=64, dropout=0.1, lr=0.0001, epochs=50, batch_size=32\n",
      "  Validation Loss: 0.024261\n",
      "\n",
      "Testing: units=64, dropout=0.1, lr=0.0001, epochs=100, batch_size=16\n",
      "  Validation Loss: 0.024041\n",
      "\n",
      "Testing: units=64, dropout=0.1, lr=0.0001, epochs=100, batch_size=32\n",
      "  Validation Loss: 0.024343\n",
      "\n",
      "Testing: units=64, dropout=0.2, lr=0.001, epochs=50, batch_size=16\n",
      "  Validation Loss: 0.023801\n",
      "\n",
      "Testing: units=64, dropout=0.2, lr=0.001, epochs=50, batch_size=32\n",
      "  Validation Loss: 0.024454\n",
      "\n",
      "Testing: units=64, dropout=0.2, lr=0.001, epochs=100, batch_size=16\n",
      "  Validation Loss: 0.020584\n",
      "\n",
      "Testing: units=64, dropout=0.2, lr=0.001, epochs=100, batch_size=32\n",
      "  Validation Loss: 0.023170\n",
      "\n",
      "Testing: units=64, dropout=0.2, lr=0.0001, epochs=50, batch_size=16\n",
      "  Validation Loss: 0.024064\n",
      "\n",
      "Testing: units=64, dropout=0.2, lr=0.0001, epochs=50, batch_size=32\n",
      "  Validation Loss: 0.024364\n",
      "\n",
      "Testing: units=64, dropout=0.2, lr=0.0001, epochs=100, batch_size=16\n",
      "  Validation Loss: 0.024170\n",
      "\n",
      "Testing: units=64, dropout=0.2, lr=0.0001, epochs=100, batch_size=32\n",
      "  Validation Loss: 0.024170\n",
      "\n",
      "Testing: units=64, dropout=0.3, lr=0.001, epochs=50, batch_size=16\n",
      "  Validation Loss: 0.025548\n",
      "\n",
      "Testing: units=64, dropout=0.3, lr=0.001, epochs=50, batch_size=32\n",
      "  Validation Loss: 0.023933\n",
      "\n",
      "Testing: units=64, dropout=0.3, lr=0.001, epochs=100, batch_size=16\n",
      "  Validation Loss: 0.024114\n",
      "\n",
      "Testing: units=64, dropout=0.3, lr=0.001, epochs=100, batch_size=32\n",
      "  Validation Loss: 0.024311\n",
      "\n",
      "Testing: units=64, dropout=0.3, lr=0.0001, epochs=50, batch_size=16\n",
      "  Validation Loss: 0.024242\n",
      "\n",
      "Testing: units=64, dropout=0.3, lr=0.0001, epochs=50, batch_size=32\n",
      "  Validation Loss: 0.024323\n",
      "\n",
      "Testing: units=64, dropout=0.3, lr=0.0001, epochs=100, batch_size=16\n",
      "  Validation Loss: 0.023940\n",
      "\n",
      "Testing: units=64, dropout=0.3, lr=0.0001, epochs=100, batch_size=32\n",
      "  Validation Loss: 0.024031\n",
      "\n",
      "Testing: units=128, dropout=0.1, lr=0.001, epochs=50, batch_size=16\n",
      "  Validation Loss: 0.021657\n",
      "\n",
      "Testing: units=128, dropout=0.1, lr=0.001, epochs=50, batch_size=32\n",
      "  Validation Loss: 0.024097\n",
      "\n",
      "Testing: units=128, dropout=0.1, lr=0.001, epochs=100, batch_size=16\n",
      "  Validation Loss: 0.013220\n",
      "\n",
      "Testing: units=128, dropout=0.1, lr=0.001, epochs=100, batch_size=32\n",
      "  Validation Loss: 0.021333\n",
      "\n",
      "Testing: units=128, dropout=0.1, lr=0.0001, epochs=50, batch_size=16\n",
      "  Validation Loss: 0.024152\n",
      "\n",
      "Testing: units=128, dropout=0.1, lr=0.0001, epochs=50, batch_size=32\n",
      "  Validation Loss: 0.024415\n",
      "\n",
      "Testing: units=128, dropout=0.1, lr=0.0001, epochs=100, batch_size=16\n",
      "  Validation Loss: 0.024152\n",
      "\n",
      "Testing: units=128, dropout=0.1, lr=0.0001, epochs=100, batch_size=32\n",
      "  Validation Loss: 0.024338\n",
      "\n",
      "Testing: units=128, dropout=0.2, lr=0.001, epochs=50, batch_size=16\n",
      "  Validation Loss: 0.022599\n",
      "\n",
      "Testing: units=128, dropout=0.2, lr=0.001, epochs=50, batch_size=32\n",
      "  Validation Loss: 0.024081\n",
      "\n",
      "Testing: units=128, dropout=0.2, lr=0.001, epochs=100, batch_size=16\n",
      "  Validation Loss: 0.014503\n",
      "\n",
      "Testing: units=128, dropout=0.2, lr=0.001, epochs=100, batch_size=32\n",
      "  Validation Loss: 0.023883\n",
      "\n",
      "Testing: units=128, dropout=0.2, lr=0.0001, epochs=50, batch_size=16\n",
      "  Validation Loss: 0.024206\n",
      "\n",
      "Testing: units=128, dropout=0.2, lr=0.0001, epochs=50, batch_size=32\n",
      "  Validation Loss: 0.024665\n",
      "\n",
      "Testing: units=128, dropout=0.2, lr=0.0001, epochs=100, batch_size=16\n",
      "  Validation Loss: 0.024162\n",
      "\n",
      "Testing: units=128, dropout=0.2, lr=0.0001, epochs=100, batch_size=32\n",
      "  Validation Loss: 0.024524\n",
      "\n",
      "Testing: units=128, dropout=0.3, lr=0.001, epochs=50, batch_size=16\n",
      "  Validation Loss: 0.022559\n",
      "\n",
      "Testing: units=128, dropout=0.3, lr=0.001, epochs=50, batch_size=32\n",
      "  Validation Loss: 0.026866\n",
      "\n",
      "Testing: units=128, dropout=0.3, lr=0.001, epochs=100, batch_size=16\n",
      "  Validation Loss: 0.019958\n",
      "\n",
      "Testing: units=128, dropout=0.3, lr=0.001, epochs=100, batch_size=32\n",
      "  Validation Loss: 0.024460\n",
      "\n",
      "Testing: units=128, dropout=0.3, lr=0.0001, epochs=50, batch_size=16\n",
      "  Validation Loss: 0.024104\n",
      "\n",
      "Testing: units=128, dropout=0.3, lr=0.0001, epochs=50, batch_size=32\n",
      "  Validation Loss: 0.024327\n",
      "\n",
      "Testing: units=128, dropout=0.3, lr=0.0001, epochs=100, batch_size=16\n",
      "  Validation Loss: 0.024231\n",
      "\n",
      "Testing: units=128, dropout=0.3, lr=0.0001, epochs=100, batch_size=32\n",
      "  Validation Loss: 0.024470\n",
      "\n",
      "\n",
      "Top 5 Configurations:\n",
      "    units  dropout  learning_rate  epochs  batch_size  val_loss\n",
      "74    128      0.1          0.001     100          16  0.013220\n",
      "82    128      0.2          0.001     100          16  0.014503\n",
      "50     64      0.1          0.001     100          16  0.015141\n",
      "26     50      0.1          0.001     100          16  0.018436\n",
      "90    128      0.3          0.001     100          16  0.019958\n",
      "\n",
      "Best Hyperparameters:\n",
      "units            128.00000\n",
      "dropout            0.10000\n",
      "learning_rate      0.00100\n",
      "epochs           100.00000\n",
      "batch_size        16.00000\n",
      "val_loss           0.01322\n",
      "Name: 74, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Define hyperparameter grid\n",
    "hyperparameters = {\n",
    "    'units': [32, 50, 64, 128],\n",
    "    'dropout_rate': [0.1, 0.2, 0.3],\n",
    "    'learning_rate': [0.001, 0.0001],\n",
    "    'epochs': [50, 100],\n",
    "    'batch_size': [16, 32]\n",
    "}\n",
    "\n",
    "# Manual grid search\n",
    "results = []\n",
    "\n",
    "for units in hyperparameters['units']:\n",
    "    for dropout in hyperparameters['dropout_rate']:\n",
    "        for lr in hyperparameters['learning_rate']:\n",
    "            for epochs in hyperparameters['epochs']:\n",
    "                for batch_size in hyperparameters['batch_size']:\n",
    "\n",
    "                    K.clear_session() \n",
    "                    \n",
    "                    print(f\"Testing: units={units}, dropout={dropout}, lr={lr}, \"\n",
    "                          f\"epochs={epochs}, batch_size={batch_size}\")\n",
    "                    \n",
    "                    model, val_loss, history = build_and_train_lstm(\n",
    "                        units, dropout, lr, epochs, batch_size\n",
    "                    )\n",
    "                    \n",
    "                    results.append({\n",
    "                        'units': units,\n",
    "                        'dropout': dropout,\n",
    "                        'learning_rate': lr,\n",
    "                        'epochs': epochs,\n",
    "                        'batch_size': batch_size,\n",
    "                        'val_loss': val_loss\n",
    "                    })\n",
    "                    \n",
    "                    print(f\"  Validation Loss: {val_loss:.6f}\\n\")\n",
    "\n",
    "# Convert to DataFrame and sort\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values('val_loss')\n",
    "\n",
    "print(\"\\nTop 5 Configurations:\")\n",
    "print(results_df.head())\n",
    "\n",
    "# Use best hyperparameters\n",
    "best_params = results_df.iloc[0]\n",
    "print(f\"\\nBest Hyperparameters:\")\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d0bb8a6-ab2e-47c4-b1dc-e7a26b09daa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Grid Search with Early Stopping...\n",
      "======================================================================\n",
      "\n",
      "[1/36] Testing configuration:\n",
      "  units=32, dropout=0.1, lr=0.001, batch_size=16\n",
      "  Best Val Loss: 0.011538\n",
      "  Epochs Trained: 200 (stopped early)\n",
      "\n",
      "[2/36] Testing configuration:\n",
      "  units=32, dropout=0.1, lr=0.001, batch_size=32\n",
      "  Best Val Loss: 0.024174\n",
      "  Epochs Trained: 19 (stopped early)\n",
      "\n",
      "[3/36] Testing configuration:\n",
      "  units=32, dropout=0.1, lr=0.0001, batch_size=16\n",
      "  Best Val Loss: 0.024117\n",
      "  Epochs Trained: 32 (stopped early)\n",
      "\n",
      "[4/36] Testing configuration:\n",
      "  units=32, dropout=0.1, lr=0.0001, batch_size=32\n",
      "  Best Val Loss: 0.024018\n",
      "  Epochs Trained: 39 (stopped early)\n",
      "\n",
      "[5/36] Testing configuration:\n",
      "  units=32, dropout=0.2, lr=0.001, batch_size=16\n",
      "  Best Val Loss: 0.014281\n",
      "  Epochs Trained: 200 (stopped early)\n",
      "\n",
      "[6/36] Testing configuration:\n",
      "  units=32, dropout=0.2, lr=0.001, batch_size=32\n",
      "  Best Val Loss: 0.021758\n",
      "  Epochs Trained: 200 (stopped early)\n",
      "\n",
      "[7/36] Testing configuration:\n",
      "  units=32, dropout=0.2, lr=0.0001, batch_size=16\n",
      "  Best Val Loss: 0.023898\n",
      "  Epochs Trained: 37 (stopped early)\n",
      "\n",
      "[8/36] Testing configuration:\n",
      "  units=32, dropout=0.2, lr=0.0001, batch_size=32\n",
      "  Best Val Loss: 0.023767\n",
      "  Epochs Trained: 53 (stopped early)\n",
      "\n",
      "[9/36] Testing configuration:\n",
      "  units=32, dropout=0.3, lr=0.001, batch_size=16\n",
      "  Best Val Loss: 0.016655\n",
      "  Epochs Trained: 200 (stopped early)\n",
      "\n",
      "[10/36] Testing configuration:\n",
      "  units=32, dropout=0.3, lr=0.001, batch_size=32\n",
      "  Best Val Loss: 0.023913\n",
      "  Epochs Trained: 22 (stopped early)\n",
      "\n",
      "[11/36] Testing configuration:\n",
      "  units=32, dropout=0.3, lr=0.0001, batch_size=16\n",
      "  Best Val Loss: 0.024167\n",
      "  Epochs Trained: 60 (stopped early)\n",
      "\n",
      "[12/36] Testing configuration:\n",
      "  units=32, dropout=0.3, lr=0.0001, batch_size=32\n",
      "  Best Val Loss: 0.023904\n",
      "  Epochs Trained: 56 (stopped early)\n",
      "\n",
      "[13/36] Testing configuration:\n",
      "  units=50, dropout=0.1, lr=0.001, batch_size=16\n",
      "  Best Val Loss: 0.011999\n",
      "  Epochs Trained: 193 (stopped early)\n",
      "\n",
      "[14/36] Testing configuration:\n",
      "  units=50, dropout=0.1, lr=0.001, batch_size=32\n",
      "  Best Val Loss: 0.014771\n",
      "  Epochs Trained: 200 (stopped early)\n",
      "\n",
      "[15/36] Testing configuration:\n",
      "  units=50, dropout=0.1, lr=0.0001, batch_size=16\n",
      "  Best Val Loss: 0.024201\n",
      "  Epochs Trained: 43 (stopped early)\n",
      "\n",
      "[16/36] Testing configuration:\n",
      "  units=50, dropout=0.1, lr=0.0001, batch_size=32\n",
      "  Best Val Loss: 0.024101\n",
      "  Epochs Trained: 36 (stopped early)\n",
      "\n",
      "[17/36] Testing configuration:\n",
      "  units=50, dropout=0.2, lr=0.001, batch_size=16\n",
      "  Best Val Loss: 0.012355\n",
      "  Epochs Trained: 200 (stopped early)\n",
      "\n",
      "[18/36] Testing configuration:\n",
      "  units=50, dropout=0.2, lr=0.001, batch_size=32\n",
      "  Best Val Loss: 0.021661\n",
      "  Epochs Trained: 200 (stopped early)\n",
      "\n",
      "[19/36] Testing configuration:\n",
      "  units=50, dropout=0.2, lr=0.0001, batch_size=16\n",
      "  Best Val Loss: 0.023833\n",
      "  Epochs Trained: 35 (stopped early)\n",
      "\n",
      "[20/36] Testing configuration:\n",
      "  units=50, dropout=0.2, lr=0.0001, batch_size=32\n",
      "  Best Val Loss: 0.024164\n",
      "  Epochs Trained: 35 (stopped early)\n",
      "\n",
      "[21/36] Testing configuration:\n",
      "  units=50, dropout=0.3, lr=0.001, batch_size=16\n",
      "  Best Val Loss: 0.014813\n",
      "  Epochs Trained: 200 (stopped early)\n",
      "\n",
      "[22/36] Testing configuration:\n",
      "  units=50, dropout=0.3, lr=0.001, batch_size=32\n",
      "  Best Val Loss: 0.022399\n",
      "  Epochs Trained: 190 (stopped early)\n",
      "\n",
      "[23/36] Testing configuration:\n",
      "  units=50, dropout=0.3, lr=0.0001, batch_size=16\n",
      "  Best Val Loss: 0.023893\n",
      "  Epochs Trained: 47 (stopped early)\n",
      "\n",
      "[24/36] Testing configuration:\n",
      "  units=50, dropout=0.3, lr=0.0001, batch_size=32\n",
      "  Best Val Loss: 0.024127\n",
      "  Epochs Trained: 59 (stopped early)\n",
      "\n",
      "[25/36] Testing configuration:\n",
      "  units=64, dropout=0.1, lr=0.001, batch_size=16\n",
      "  Best Val Loss: 0.011874\n",
      "  Epochs Trained: 162 (stopped early)\n",
      "\n",
      "[26/36] Testing configuration:\n",
      "  units=64, dropout=0.1, lr=0.001, batch_size=32\n",
      "  Best Val Loss: 0.023622\n",
      "  Epochs Trained: 83 (stopped early)\n",
      "\n",
      "[27/36] Testing configuration:\n",
      "  units=64, dropout=0.1, lr=0.0001, batch_size=16\n",
      "  Best Val Loss: 0.024019\n",
      "  Epochs Trained: 74 (stopped early)\n",
      "\n",
      "[28/36] Testing configuration:\n",
      "  units=64, dropout=0.1, lr=0.0001, batch_size=32\n",
      "  Best Val Loss: 0.024217\n",
      "  Epochs Trained: 30 (stopped early)\n",
      "\n",
      "[29/36] Testing configuration:\n",
      "  units=64, dropout=0.2, lr=0.001, batch_size=16\n",
      "  Best Val Loss: 0.012022\n",
      "  Epochs Trained: 183 (stopped early)\n",
      "\n",
      "[30/36] Testing configuration:\n",
      "  units=64, dropout=0.2, lr=0.001, batch_size=32\n",
      "  Best Val Loss: 0.015783\n",
      "  Epochs Trained: 200 (stopped early)\n",
      "\n",
      "[31/36] Testing configuration:\n",
      "  units=64, dropout=0.2, lr=0.0001, batch_size=16\n",
      "  Best Val Loss: 0.024133\n",
      "  Epochs Trained: 52 (stopped early)\n",
      "\n",
      "[32/36] Testing configuration:\n",
      "  units=64, dropout=0.2, lr=0.0001, batch_size=32\n",
      "  Best Val Loss: 0.024152\n",
      "  Epochs Trained: 30 (stopped early)\n",
      "\n",
      "[33/36] Testing configuration:\n",
      "  units=64, dropout=0.3, lr=0.001, batch_size=16\n",
      "  Best Val Loss: 0.012851\n",
      "  Epochs Trained: 200 (stopped early)\n",
      "\n",
      "[34/36] Testing configuration:\n",
      "  units=64, dropout=0.3, lr=0.001, batch_size=32\n",
      "  Best Val Loss: 0.020846\n",
      "  Epochs Trained: 200 (stopped early)\n",
      "\n",
      "[35/36] Testing configuration:\n",
      "  units=64, dropout=0.3, lr=0.0001, batch_size=16\n",
      "  Best Val Loss: 0.023876\n",
      "  Epochs Trained: 61 (stopped early)\n",
      "\n",
      "[36/36] Testing configuration:\n",
      "  units=64, dropout=0.3, lr=0.0001, batch_size=32\n",
      "  Best Val Loss: 0.024067\n",
      "  Epochs Trained: 42 (stopped early)\n",
      "\n",
      "======================================================================\n",
      "Grid Search Complete!\n",
      "\n",
      "ðŸ“Š Top 5 Configurations:\n",
      "    units  dropout  learning_rate  batch_size  val_loss  epochs_trained\n",
      "0      32      0.1          0.001          16  0.011538             200\n",
      "24     64      0.1          0.001          16  0.011874             162\n",
      "12     50      0.1          0.001          16  0.011999             193\n",
      "28     64      0.2          0.001          16  0.012022             183\n",
      "16     50      0.2          0.001          16  0.012355             200\n",
      "32     64      0.3          0.001          16  0.012851             200\n",
      "4      32      0.2          0.001          16  0.014281             200\n",
      "13     50      0.1          0.001          32  0.014771             200\n",
      "20     50      0.3          0.001          16  0.014813             200\n",
      "29     64      0.2          0.001          32  0.015783             200\n",
      "\n",
      "ðŸ† Best Configuration:\n",
      "  Units: 32.0\n",
      "  Dropout: 0.1\n",
      "  Learning Rate: 0.001\n",
      "  Batch Size: 16.0\n",
      "  Best Val Loss: 0.011538\n",
      "  Epochs: 200.0\n",
      "\n",
      "âœ… Results saved to 'grid_search_results.csv'\n"
     ]
    }
   ],
   "source": [
    "def build_and_train_lstm_2(units, dropout_rate, learning_rate, batch_size, max_epochs=200):\n",
    "    \"\"\"\n",
    "    Build and train LSTM with early stopping\n",
    "    \"\"\"\n",
    "    # Build model\n",
    "    model = Sequential([\n",
    "        Input(shape=(T, 1)),\n",
    "        LSTM(units, activation='tanh', return_sequences=True),\n",
    "        Dropout(dropout_rate),\n",
    "        LSTM(units, activation='tanh'),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mse')\n",
    "    \n",
    "    # Define early stopping callback\n",
    "    early_stop = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=15,  # Stop if no improvement for 15 epochs\n",
    "        restore_best_weights=True,  # Restore weights from best epoch\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    # Train with early stopping\n",
    "    history = model.fit(\n",
    "        Xtrain, Ytrain,\n",
    "        epochs=max_epochs,  # Set high, early stopping will stop earlier\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(Xtest, Ytest),\n",
    "        callbacks=[early_stop],\n",
    "        verbose=0,\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    # Get best validation loss and actual epochs trained\n",
    "    val_loss = min(history.history['val_loss'])\n",
    "    epochs_trained = len(history.history['loss'])\n",
    "    \n",
    "    return model, val_loss, epochs_trained, history\n",
    "\n",
    "# Define hyperparameter grid\n",
    "hyperparameters = {\n",
    "    'units': [32, 50, 64],\n",
    "    'dropout_rate': [0.1, 0.2, 0.3],\n",
    "    'learning_rate': [0.001, 0.0001],\n",
    "    'batch_size': [16, 32]\n",
    "}\n",
    "\n",
    "# Grid search with early stopping\n",
    "results = []\n",
    "\n",
    "print(\"Starting Grid Search with Early Stopping...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "total_combinations = (len(hyperparameters['units']) * \n",
    "                     len(hyperparameters['dropout_rate']) * \n",
    "                     len(hyperparameters['learning_rate']) * \n",
    "                     len(hyperparameters['batch_size']))\n",
    "\n",
    "iteration = 0\n",
    "\n",
    "for units in hyperparameters['units']:\n",
    "    for dropout in hyperparameters['dropout_rate']:\n",
    "        for lr in hyperparameters['learning_rate']:\n",
    "            for batch_size in hyperparameters['batch_size']:\n",
    "                \n",
    "                iteration += 1\n",
    "                print(f\"\\n[{iteration}/{total_combinations}] Testing configuration:\")\n",
    "                print(f\"  units={units}, dropout={dropout}, lr={lr}, batch_size={batch_size}\")\n",
    "                \n",
    "                model, val_loss, epochs_trained, history = build_and_train_lstm_2(\n",
    "                    units, dropout, lr, batch_size, max_epochs=200\n",
    "                )\n",
    "                \n",
    "                results.append({\n",
    "                    'units': units,\n",
    "                    'dropout': dropout,\n",
    "                    'learning_rate': lr,\n",
    "                    'batch_size': batch_size,\n",
    "                    'val_loss': val_loss,\n",
    "                    'epochs_trained': epochs_trained\n",
    "                })\n",
    "                \n",
    "                print(f\"  Best Val Loss: {val_loss:.6f}\")\n",
    "                print(f\"  Epochs Trained: {epochs_trained} (stopped early)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Grid Search Complete!\")\n",
    "\n",
    "# Convert to DataFrame and analyze\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values('val_loss')\n",
    "\n",
    "print(\"\\nðŸ“Š Top 5 Configurations:\")\n",
    "print(results_df.head(10))\n",
    "\n",
    "print(\"\\nðŸ† Best Configuration:\")\n",
    "best = results_df.iloc[0]\n",
    "print(f\"  Units: {best['units']}\")\n",
    "print(f\"  Dropout: {best['dropout']}\")\n",
    "print(f\"  Learning Rate: {best['learning_rate']}\")\n",
    "print(f\"  Batch Size: {best['batch_size']}\")\n",
    "print(f\"  Best Val Loss: {best['val_loss']:.6f}\")\n",
    "print(f\"  Epochs: {best['epochs_trained']}\")\n",
    "\n",
    "# Save results\n",
    "results_df.to_csv('grid_search_results.csv', index=False)\n",
    "print(\"\\nâœ… Results saved to 'grid_search_results.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow (tf)",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
